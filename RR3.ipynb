{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoboReviews Project\n",
    "#### The new product review aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from transformers import RobertaTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = '/notebooks/combined_amazon_reviews.csv'\n",
    "df = pd.read_csv(dataset_path, low_memory=False)\n",
    "\n",
    "# Define the columns to keep\n",
    "columns_to_keep = ['name', 'brand', 'primaryCategories', 'reviews.rating', 'reviews.text']\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "# Handle missing values in 'reviews.text' and 'reviews.rating'\n",
    "# We use .loc to avoid SettingWithCopyWarning\n",
    "df_cleaned.loc[:, 'reviews.text'] = df_cleaned['reviews.text'].fillna('No review text provided.')\n",
    "df_cleaned.loc[:, 'reviews.rating'] = df_cleaned['reviews.rating'].fillna(df_cleaned['reviews.rating'].median())\n",
    "\n",
    "# Display the cleaned dataset\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Data Visualization\n",
    "# Check and visualize the distribution of ratings\n",
    "rating_counts = df_cleaned['reviews.rating'].value_counts().sort_index()\n",
    "print(rating_counts)\n",
    "\n",
    "# Plot the distribution of ratings\n",
    "plt.figure(figsize=(8, 6))\n",
    "rating_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Ratings from 0 to 5')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True)  # Added gridlines for better readability\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and extra spaces\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'reviews.text' column\n",
    "df_cleaned['reviews.text'] = df_cleaned['reviews.text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few preprocessed reviews\n",
    "print(df_cleaned['reviews.text'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Predicting Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the sentiment analysis model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize and Predict Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™ll process the reviews in batches, tokenize them as a group, and then predict their sentiments. Instead of using apply, we can directly tokenize and predict for all the reviews together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Function to predict sentiment for a batch of reviews\n",
    "def predict_sentiment_batch(reviews):\n",
    "    # Tokenize the batch of review texts\n",
    "    inputs = tokenizer(reviews, truncation=True, padding=True, return_tensors=\"pt\", max_length=512)\n",
    "    \n",
    "    # Perform sentiment prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get the predicted sentiment labels (0 = Negative, 1 = Neutral, 2 = Positive)\n",
    "    predicted_labels = torch.argmax(probabilities, dim=1).tolist()\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "# Batch size to process reviews in chunks (choose an appropriate size)\n",
    "batch_size = 32\n",
    "\n",
    "# Apply sentiment prediction in batches\n",
    "sentiment_predictions = []\n",
    "for i in range(0, len(df_cleaned), batch_size):\n",
    "    batch_reviews = df_cleaned['reviews.text'][i:i+batch_size].tolist()  # Get batch of reviews\n",
    "    batch_predictions = predict_sentiment_batch(batch_reviews)  # Predict sentiment for the batch\n",
    "    sentiment_predictions.extend(batch_predictions)  # Store the batch predictions\n",
    "\n",
    "# Add predicted sentiments back to the dataframe\n",
    "df_cleaned['sentiment'] = sentiment_predictions\n",
    "\n",
    "# Display the first few rows with predicted sentiment labels\n",
    "print(df_cleaned[['reviews.text', 'sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Sentiment Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check the distribution of sentiment labels\n",
    "sentiment_counts = df_cleaned['sentiment'].value_counts()\n",
    "\n",
    "# Plot the distribution of sentiments\n",
    "plt.figure(figsize=(6, 4))\n",
    "sentiment_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.xlabel('Sentiment (0 = Negative, 1 = Neutral, 2 = Positive)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fee3e0ba2d0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fee355d3790, raw_cell=\"# Select relevant columns for classification (e.g...\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/fmrol/Documents/GitHub/RobotReviews/RR3.ipynb#Y234sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_393/3408380196.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select relevant columns for classification (e.g., reviews.text and primaryCategories)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'primaryCategories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Optional: If product categories have many subcategories, map them to broader groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# For example, mapping different subcategories to broader product categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6289\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6290\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6291\u001b[0m         ):\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'select'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fee3e0ba2d0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fee358e1110, execution_count=39 error_before_exec=None error_in_exec='DataFrame' object has no attribute 'select' info=<ExecutionInfo object at 7fee355d3790, raw_cell=\"# Select relevant columns for classification (e.g...\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/fmrol/Documents/GitHub/RobotReviews/RR3.ipynb#Y234sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Select relevant columns for classification (e.g., reviews.text and primaryCategories)\n",
    "df_classification = df_cleaned.select(['reviews.text', 'primaryCategories'])\n",
    "\n",
    "# Optional: If product categories have many subcategories, map them to broader groups\n",
    "# For example, mapping different subcategories to broader product categories\n",
    "category_mapping = {\n",
    "    \"Electronics\": [\"Phones\", \"Computers\", \"Tablets\"],\n",
    "    \"Health & Beauty\": [\"Skincare\", \"Makeup\"]\n",
    "}\n",
    "\n",
    "df_classification = df_classification.with_columns([\n",
    "    pl.when(pl.col(\"primaryCategories\").is_in(category_mapping[\"Electronics\"])).then(\"Electronics\")\n",
    "      .when(pl.col(\"primaryCategories\").is_in(category_mapping[\"Health & Beauty\"])).then(\"Health & Beauty\")\n",
    "      .otherwise(pl.col(\"primaryCategories\")).alias(\"primaryCategories\")\n",
    "])\n",
    "\n",
    "# Check the classification dataset\n",
    "print(df_classification.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fee3e0ba2d0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fee355d3790, raw_cell=\"# Select relevant columns for classification (e.g...\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/fmrol/Documents/GitHub/RobotReviews/RR3.ipynb#Y234sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[0;32m/tmp/ipykernel_393/3408380196.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;31m# Select relevant columns for classification (e.g., reviews.text and primaryCategories)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cleaned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reviews.text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'primaryCategories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;31m# Optional: If product categories have many subcategories, map them to broader groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[0;31m# For example, mapping different subcategories to broader product categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n",
      "\u001b[1;32m   6289\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   6290\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   6291\u001b[0m         ):\n",
      "\u001b[1;32m   6292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 6293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'select'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fee3e0ba2d0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fee358e1110, execution_count=39 error_before_exec=None error_in_exec='DataFrame' object has no attribute 'select' info=<ExecutionInfo object at 7fee355d3790, raw_cell=\"# Select relevant columns for classification (e.g...\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/fmrol/Documents/GitHub/RobotReviews/RR3.ipynb#Y234sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Select relevant columns for classification (e.g., reviews.text and primaryCategories)\n",
    "df_classification = df_cleaned.select(['reviews.text', 'primaryCategories'])\n",
    "\n",
    "# Optional: If product categories have many subcategories, map them to broader groups\n",
    "# For example, mapping different subcategories to broader product categories\n",
    "category_mapping = {\n",
    "    \"Electronics\": [\"Phones\", \"Computers\", \"Tablets\"],\n",
    "    \"Health & Beauty\": [\"Skincare\", \"Makeup\"]\n",
    "}\n",
    "\n",
    "df_classification = df_classification.with_columns([\n",
    "    pl.when(pl.col(\"primaryCategories\").is_in(category_mapping[\"Electronics\"])).then(\"Electronics\")\n",
    "      .when(pl.col(\"primaryCategories\").is_in(category_mapping[\"Health & Beauty\"])).then(\"Health & Beauty\")\n",
    "      .otherwise(pl.col(\"primaryCategories\")).alias(\"primaryCategories\")\n",
    "])\n",
    "\n",
    "# Check the classification dataset\n",
    "print(df_classification.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convert text and sentiment columns to lists for splitting\n",
    "texts = df_cleaned['reviews.text'].to_list()\n",
    "labels = df_cleaned['sentiment'].to_list()\n",
    "\n",
    "# Split the data into training and test sets (80/20 split)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained('./fine-tuned-roberta-sentiment')\n",
    "tokenizer.save_pretrained('./fine-tuned-roberta-sentiment')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very imbalanced. This means that later we will have to use some methods to deal with that.\n",
    "- Class Weights: Adjust the loss function to account for class imbalances during training.\n",
    "- Oversampling/Undersampling: Oversample the minority classes (e.g., negative reviews) or undersample the majority class (positive reviews) before training.\n",
    "- SMOTE: Synthetic Minority Oversampling Technique (SMOTE) could also be used to generate synthetic examples for the minority class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
