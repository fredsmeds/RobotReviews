{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoboReviews Project\n",
    "#### The new product review aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:53:49.480077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 15:53:49.480176: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 15:53:49.481162: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 15:53:49.487624: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 15:53:50.307673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name         brand  \\\n",
       "0  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "2  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "3  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "4  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "\n",
       "  primaryCategories                                       reviews.text  \\\n",
       "0   Health & Beauty  I order 3 of them and one of the item is bad q...   \n",
       "1   Health & Beauty  Bulk is always the less expensive way to go fo...   \n",
       "2   Health & Beauty  Well they are not Duracell but for the price i...   \n",
       "3   Health & Beauty  Seem to work as well as name brand batteries a...   \n",
       "4   Health & Beauty  These batteries are very long lasting the pric...   \n",
       "\n",
       "   reviews.rating  \n",
       "0               3  \n",
       "1               4  \n",
       "2               5  \n",
       "3               5  \n",
       "4               5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/notebooks/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv'  # Replace with the correct file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Select the specified columns\n",
    "columns_to_keep = ['name', 'brand', 'primaryCategories', 'reviews.text', 'reviews.rating']\n",
    "df_selected = df[columns_to_keep]\n",
    "\n",
    "# Show the first few rows to verify\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews.rating\n",
      "2    29856\n",
      "0    25545\n",
      "1    21234\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate the dataset by rating categories (assume 1-2 is negative, 3 is neutral, 4-5 is positive)\n",
    "positive_reviews = df_selected[df_selected['reviews.rating'] >= 4]\n",
    "neutral_reviews = df_selected[df_selected['reviews.rating'] == 3]\n",
    "negative_reviews = df_selected[df_selected['reviews.rating'] <= 2]\n",
    "\n",
    "# Find the class with the most samples\n",
    "max_class_size = max(len(positive_reviews), len(neutral_reviews), len(negative_reviews))\n",
    "\n",
    "# Oversample the minority classes to match the largest class\n",
    "positive_upsampled = resample(positive_reviews, replace=True, n_samples=max_class_size, random_state=42)\n",
    "neutral_upsampled = resample(neutral_reviews, replace=True, n_samples=max_class_size, random_state=42)\n",
    "negative_upsampled = resample(negative_reviews, replace=True, n_samples=max_class_size, random_state=42)\n",
    "\n",
    "# Combine the upsampled datasets\n",
    "df_balanced = pd.concat([positive_upsampled, neutral_upsampled, negative_upsampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# After balancing the dataset\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Map the labels to a new range\n",
    "df_balanced['reviews.rating'] = df_balanced['reviews.rating'].map({0: 0, 1: 1, 2: 2, 3: 0, 4: 1, 5: 2})\n",
    "\n",
    "\n",
    "\n",
    "# Verify class balance\n",
    "print(df_balanced['reviews.rating'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_sentiment(rating):\n",
    "    if rating <= 2:\n",
    "        return 0  # negative\n",
    "    elif rating == 3:\n",
    "        return 1  # neutral\n",
    "    else:\n",
    "        return 2  # positive\n",
    "\n",
    "df_balanced['labels'] = df_balanced['reviews.rating'].apply(map_to_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset before tokenization\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_balanced['reviews.text'], df_balanced['reviews.rating'], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenize training and testing sets with padding and truncation\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding='max_length', max_length=512, return_tensors='pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train encodings shape: torch.Size([61308, 512])\n",
      "Test encodings shape: torch.Size([15327, 512])\n",
      "Train attention mask shape: torch.Size([61308, 512])\n",
      "Test attention mask shape: torch.Size([15327, 512])\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes to verify consistency\n",
    "print(f\"Train encodings shape: {train_encodings['input_ids'].shape}\")\n",
    "print(f\"Test encodings shape: {test_encodings['input_ids'].shape}\")\n",
    "\n",
    "# Check attention mask shapes\n",
    "print(f\"Train attention mask shape: {train_encodings['attention_mask'].shape}\")\n",
    "print(f\"Test attention mask shape: {test_encodings['attention_mask'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Datasets with matching lenghts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Create HuggingFace Datasets for training and test data\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'].tolist(),\n",
    "    'attention_mask': train_encodings['attention_mask'].tolist(),\n",
    "    'labels': y_train.tolist()\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'].tolist(),\n",
    "    'attention_mask': test_encodings['attention_mask'].tolist(),\n",
    "    'labels': y_test.tolist()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length: 61308\n",
      "Test dataset length: 15327\n"
     ]
    }
   ],
   "source": [
    "# Verify the shape of the dataset to ensure proper tokenization\n",
    "print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "print(f\"Test dataset length: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrating LoRA for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Assuming you have already tokenized the data correctly as seen in the previous images\n",
    "# Tokenization (already done by you)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "# Define LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # Sequence classification task\n",
    "    r=8,  # Low-rank adaptation dimension\n",
    "    lora_alpha=32,  # LoRA scaling factor\n",
    "    lora_dropout=0.1,  # Dropout in LoRA layers\n",
    "    target_modules=[\"q_lin\", \"v_lin\"]  # Target modules for LoRA in DistilBERT (MultiHeadAttention)\n",
    ")\n",
    "\n",
    "# Load pretrained model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased', \n",
    "    num_labels=3  # Adjust based on your labels (e.g. positive, negative, neutral)\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA using PEFT\n",
    "model = get_peft_model(model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,  # Adjust based on your need\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    "    no_cuda=False  # Assuming you have a GPU, if not set to True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfmroldanrivero\u001b[0m (\u001b[33mfredsmeds\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/wandb/run-20241016_160822-tj5skis9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fredsmeds/huggingface/runs/tj5skis9' target=\"_blank\">laced-shadow-22</a></strong> to <a href='https://wandb.ai/fredsmeds/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fredsmeds/huggingface' target=\"_blank\">https://wandb.ai/fredsmeds/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fredsmeds/huggingface/runs/tj5skis9' target=\"_blank\">https://wandb.ai/fredsmeds/huggingface/runs/tj5skis9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11496' max='11496' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11496/11496 29:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.786800</td>\n",
       "      <td>0.738162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>0.653341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.726700</td>\n",
       "      <td>0.624068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11496, training_loss=0.7425901326522615, metrics={'train_runtime': 1805.0683, 'train_samples_per_second': 101.893, 'train_steps_per_second': 6.369, 'total_flos': 2.4782679657455616e+16, 'train_loss': 0.7425901326522615, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fc0c83720d0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fc0cae69b50, execution_count=15 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fc0af08c110, raw_cell=\"# Create HuggingFace Datasets for training and tes..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/c%3A/Users/fmrol/Documents/GitHub/RobotReviews/RR3.ipynb#X43sZmlsZQ%3D%3D> result=TrainOutput(global_step=11496, training_loss=0.7425901326522615, metrics={'train_runtime': 1805.0683, 'train_samples_per_second': 101.893, 'train_steps_per_second': 6.369, 'total_flos': 2.4782679657455616e+16, 'train_loss': 0.7425901326522615, 'epoch': 3.0})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Create HuggingFace Datasets for training and testing data (already done by you)\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'].tolist(),\n",
    "    'attention_mask': train_encodings['attention_mask'].tolist(),\n",
    "    'labels': y_train.tolist()\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'].tolist(),\n",
    "    'attention_mask': test_encodings['attention_mask'].tolist(),\n",
    "    'labels': y_test.tolist()\n",
    "})\n",
    "\n",
    "# Define the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,  # PEFT-wrapped model\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Fine-tune the model with LoRA\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evlatuate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the fine-tuned model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save_pretrained('./fine_tuned_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is very imbalanced. This means that later we will have to use some methods to deal with that.\n",
    "- Class Weights: Adjust the loss function to account for class imbalances during training.\n",
    "- Oversampling/Undersampling: Oversample the minority classes (e.g., negative reviews) or undersample the majority class (positive reviews) before training.\n",
    "- SMOTE: Synthetic Minority Oversampling Technique (SMOTE) could also be used to generate synthetic examples for the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
