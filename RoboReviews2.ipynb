{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoboReviews Project\n",
    "#### The new product review aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand',\n",
      "       'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer',\n",
      "       'manufacturerNumber', 'reviews.date', 'reviews.dateSeen',\n",
      "       'reviews.didPurchase', 'reviews.doRecommend', 'reviews.id',\n",
      "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
      "       'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs',\n",
      "       'reviews.dateAdded', 'reviews.userCity', 'reviews.userProvince'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48/3836848997.py:5: DtypeWarning: Columns (1,2,3,7,8,11,14,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(dataset_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = r'/notebooks/combined_amazon_reviews.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing unnecesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Preview:\n",
      "                                                name         brand  \\\n",
      "0  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "1  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "2  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "3  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "4  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "\n",
      "  primaryCategories  reviews.rating  \\\n",
      "0   Health & Beauty             3.0   \n",
      "1   Health & Beauty             4.0   \n",
      "2   Health & Beauty             5.0   \n",
      "3   Health & Beauty             5.0   \n",
      "4   Health & Beauty             5.0   \n",
      "\n",
      "                                        reviews.text  \n",
      "0  I order 3 of them and one of the item is bad q...  \n",
      "1  Bulk is always the less expensive way to go fo...  \n",
      "2  Well they are not Duracell but for the price i...  \n",
      "3  Seem to work as well as name brand batteries a...  \n",
      "4  These batteries are very long lasting the pric...  \n",
      "Remaining Columns:\n",
      "Index(['name', 'brand', 'primaryCategories', 'reviews.rating', 'reviews.text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['name', 'brand', 'primaryCategories', 'reviews.rating', 'reviews.text']\n",
    "\n",
    "# Drop the columns that are not in the 'columns_to_keep' list\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "# Verify the cleaned dataset\n",
    "print(\"Cleaned Dataset Preview:\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Check the remaining columns\n",
    "print(\"Remaining Columns:\")\n",
    "print(df_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and Clean Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "name                  6760\n",
      "primaryCategories    34660\n",
      "reviews.rating          33\n",
      "reviews.text             1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in all columns\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "\n",
    "# Display only columns that have missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "name                  6759\n",
      "brand                    0\n",
      "primaryCategories    34626\n",
      "reviews.rating           0\n",
      "reviews.text             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'reviews.text' or 'reviews.rating' are missing\n",
    "df_cleaned = df_cleaned.dropna(subset=['reviews.text', 'reviews.rating'])\n",
    "\n",
    "# Verify if missing values are removed\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing Steps:\n",
    "We will do some minimum text preprocessing since later we will use the BERT tokenizer for BERT-base-uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        reviews.text  \\\n",
      "0  I order 3 of them and one of the item is bad q...   \n",
      "1  Bulk is always the less expensive way to go fo...   \n",
      "2  Well they are not Duracell but for the price i...   \n",
      "3  Seem to work as well as name brand batteries a...   \n",
      "4  These batteries are very long lasting the pric...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  i order 3 of them and one of the item is bad q...  \n",
      "1  bulk is always the less expensive way to go fo...  \n",
      "2  well they are not duracell but for the price i...  \n",
      "3  seem to work as well as name brand batteries a...  \n",
      "4  these batteries are very long lasting the pric...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Minimal preprocessing function (to prepare text for BERT tokenizer)\n",
    "def preprocess_text_for_bert(text):\n",
    "    # Convert to lowercase (for 'uncased' models; skip this for 'cased' models)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing function to 'reviews.text'\n",
    "df_cleaned['cleaned_text'] = df_cleaned['reviews.text'].apply(preprocess_text_for_bert)\n",
    "\n",
    "# Preview the cleaned text\n",
    "print(df_cleaned[['reviews.text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>i order 3 of them and one of the item is bad q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>bulk is always the less expensive way to go fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>well they are not duracell but for the price i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>seem to work as well as name brand batteries a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>these batteries are very long lasting the pric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name         brand  \\\n",
       "0  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "2  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "3  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "4  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "\n",
       "  primaryCategories  reviews.rating  \\\n",
       "0   Health & Beauty             3.0   \n",
       "1   Health & Beauty             4.0   \n",
       "2   Health & Beauty             5.0   \n",
       "3   Health & Beauty             5.0   \n",
       "4   Health & Beauty             5.0   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "3  Seem to work as well as name brand batteries a...   \n",
       "4  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  i order 3 of them and one of the item is bad q...  \n",
       "1  bulk is always the less expensive way to go fo...  \n",
       "2  well they are not duracell but for the price i...  \n",
       "3  seem to work as well as name brand batteries a...  \n",
       "4  these batteries are very long lasting the pric...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Tokenization for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70aeda47abbf46b9ba9990cd90479b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe6d208d71a4e66a9b543a9c32c613e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabf25d5723a4bac83df34a76d538c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ab5ed4cc104d28a17099b20c8cf25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  2344,  1017,  1997,  2068,  1998,  2028,  1997,  1996,\n",
      "          8875,  2003,  2919,  3737,  1012,  2003,  4394, 10200,  3500,  2061,\n",
      "          1045,  2031,  2000,  2404,  1037, 27019,  1997, 13061,  2000,  2191,\n",
      "          1996,  6046,  2147,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the 'cleaned_text' column using BERT tokenizer\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize a single example for testing\n",
    "sample_text = df_cleaned['cleaned_text'][0]\n",
    "tokenized_output = tokenize_text(sample_text)\n",
    "print(tokenized_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the entire dataset (reviews.text)\n",
    "# Store tokenized input IDs and attention masks\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for review in df_cleaned['cleaned_text']:\n",
    "    encoded_review = tokenize_text(review)\n",
    "    input_ids.append(encoded_review['input_ids'])\n",
    "    attention_masks.append(encoded_review['attention_mask'])\n",
    "\n",
    "# Convert lists to tensors for later use with BERT\n",
    "print(\"Tokenization complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up BERT based model for sentiment classification\n",
    "we will map both reviews.rating and reviews.text columns to obtain a more accurate sentiment, instead of only the numerical rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping reviews.rating to Sentiment Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviews.rating  rating_sentiment\n",
      "0             3.0                 1\n",
      "1             4.0                 2\n",
      "2             5.0                 2\n",
      "3             5.0                 2\n",
      "4             5.0                 2\n"
     ]
    }
   ],
   "source": [
    "# Function to derive sentiment from reviews.rating\n",
    "def map_rating_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 2  # Positive\n",
    "    elif rating == 3:\n",
    "        return 1  # Neutral\n",
    "    else:\n",
    "        return 0  # Negative\n",
    "\n",
    "# Create sentiment labels based on ratings\n",
    "df_cleaned['rating_sentiment'] = df_cleaned['reviews.rating'].apply(map_rating_sentiment)\n",
    "\n",
    "# Check the rating sentiment labels\n",
    "print(df_cleaned[['reviews.rating', 'rating_sentiment']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a Pre-trained Sentiment Analysis Model for reviews.text (using distibert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 09:50:42.216597: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-15 09:50:42.216703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-15 09:50:42.217704: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-15 09:50:42.224379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 09:50:43.059496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647df6dd8a4d4433acc07d61931c4da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d122d0b9f445729c2d80b4fe252282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86374f6f94f44be697cd38940d5ef7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c45029f4a242f8b35a45201eeb80d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1181 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained sentiment analysis model from Hugging Face\n",
    "sentiment_analyzer = pipeline(\"text-classification\", model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Function to analyze review text sentiment using the pre-trained model\n",
    "def analyze_review_sentiment(review_text):\n",
    "    try:\n",
    "        analysis = sentiment_analyzer(review_text)[0]\n",
    "        if analysis['label'] == 'POSITIVE':\n",
    "            return 2  # Positive\n",
    "        elif analysis['label'] == 'NEGATIVE':\n",
    "            return 0  # Negative\n",
    "        else:\n",
    "            return 1  # Neutral\n",
    "    except:\n",
    "        return 1  # If there's an error or too short text, mark as neutral\n",
    "\n",
    "# Apply the sentiment analysis model to 'reviews.text'\n",
    "df_cleaned['text_sentiment'] = df_cleaned['reviews.text'].apply(analyze_review_sentiment)\n",
    "\n",
    "# Check the text sentiment labels\n",
    "print(df_cleaned[['reviews.text', 'text_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine reviews.rating and reviews.text Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine rating and text sentiment to derive final sentiment\n",
    "def combine_sentiments(rating_sentiment, text_sentiment):\n",
    "    # If the rating is neutral, we rely on the text sentiment\n",
    "    if rating_sentiment == 1:  # Neutral rating\n",
    "        return text_sentiment\n",
    "    else:\n",
    "        # Otherwise, prioritize the rating sentiment\n",
    "        return rating_sentiment\n",
    "\n",
    "# Apply the function to combine both sentiments\n",
    "df_cleaned['final_sentiment'] = df_cleaned.apply(lambda row: combine_sentiments(row['rating_sentiment'], row['text_sentiment']), axis=1)\n",
    "\n",
    "# Check the final sentiment labels\n",
    "print(df_cleaned[['reviews.rating', 'reviews.text', 'rating_sentiment', 'text_sentiment', 'final_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Convert input_ids and attention_masks to tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(df_cleaned['sentiment'].values)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\n",
    "train_masks, val_masks = train_test_split(attention_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Move data to the GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_inputs, train_masks, train_labels = train_inputs.to(device), train_masks.to(device), train_labels.to(device)\n",
    "val_inputs, val_masks, val_labels = val_inputs.to(device), val_masks.to(device), val_labels.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
