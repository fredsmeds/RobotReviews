{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoboReviews Project\n",
    "#### The new product review aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Dataset and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'dateAdded', 'dateUpdated', 'name', 'asins', 'brand',\n",
      "       'categories', 'primaryCategories', 'imageURLs', 'keys', 'manufacturer',\n",
      "       'manufacturerNumber', 'reviews.date', 'reviews.dateSeen',\n",
      "       'reviews.didPurchase', 'reviews.doRecommend', 'reviews.id',\n",
      "       'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs',\n",
      "       'reviews.text', 'reviews.title', 'reviews.username', 'sourceURLs',\n",
      "       'reviews.dateAdded', 'reviews.userCity', 'reviews.userProvince'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152/3836848997.py:5: DtypeWarning: Columns (1,2,3,7,8,11,14,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(dataset_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = r'/notebooks/combined_amazon_reviews.csv'\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing unnecesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Preview:\n",
      "                                                name         brand  \\\n",
      "0  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "1  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "2  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "3  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "4  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
      "\n",
      "  primaryCategories  reviews.rating  \\\n",
      "0   Health & Beauty             3.0   \n",
      "1   Health & Beauty             4.0   \n",
      "2   Health & Beauty             5.0   \n",
      "3   Health & Beauty             5.0   \n",
      "4   Health & Beauty             5.0   \n",
      "\n",
      "                                        reviews.text  \n",
      "0  I order 3 of them and one of the item is bad q...  \n",
      "1  Bulk is always the less expensive way to go fo...  \n",
      "2  Well they are not Duracell but for the price i...  \n",
      "3  Seem to work as well as name brand batteries a...  \n",
      "4  These batteries are very long lasting the pric...  \n",
      "Remaining Columns:\n",
      "Index(['name', 'brand', 'primaryCategories', 'reviews.rating', 'reviews.text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to keep\n",
    "columns_to_keep = ['name', 'brand', 'primaryCategories', 'reviews.rating', 'reviews.text']\n",
    "\n",
    "# Drop the columns that are not in the 'columns_to_keep' list\n",
    "df_cleaned = df[columns_to_keep]\n",
    "\n",
    "# Verify the cleaned dataset\n",
    "print(\"Cleaned Dataset Preview:\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Check the remaining columns\n",
    "print(\"Remaining Columns:\")\n",
    "print(df_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and Handle Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "name                  6760\n",
      "primaryCategories    34660\n",
      "reviews.rating          33\n",
      "reviews.text             1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in all columns\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "\n",
    "# Display only columns that have missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not clean missing values, since the Rating and the Text are important. instead, we will fill missing ratings with the median rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing text with a placeholder\n",
    "df_cleaned.loc[:, 'reviews.text'] = df_cleaned['reviews.text'].fillna('No review text provided.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ratings from 0 to 5:\n",
      "reviews.rating\n",
      "1.0     1438\n",
      "2.0     1072\n",
      "3.0     2902\n",
      "4.0    15397\n",
      "5.0    47150\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the count of ratings from 0 to 5 in the dataset\n",
    "rating_counts = df_cleaned['reviews.rating'].value_counts().sort_index()\n",
    "\n",
    "# Display the count of ratings from 0 to 5\n",
    "print(\"Count of ratings from 0 to 5:\")\n",
    "print(rating_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize it with a bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of ratings\n",
    "plt.figure(figsize=(8, 6))\n",
    "rating_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Ratings from 0 to 5')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing Steps:\n",
    "We will do some minimum text preprocessing since later we will use the BERT tokenizer for BERT-base-uncased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        reviews.text  \\\n",
      "0  I order 3 of them and one of the item is bad q...   \n",
      "1  Bulk is always the less expensive way to go fo...   \n",
      "2  Well they are not Duracell but for the price i...   \n",
      "3  Seem to work as well as name brand batteries a...   \n",
      "4  These batteries are very long lasting the pric...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  i order 3 of them and one of the item is bad q...  \n",
      "1  bulk is always the less expensive way to go fo...  \n",
      "2  well they are not duracell but for the price i...  \n",
      "3  seem to work as well as name brand batteries a...  \n",
      "4  these batteries are very long lasting the pric...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152/3067902798.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['cleaned_text'] = df_cleaned['reviews.text'].apply(preprocess_text_for_bert)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Minimal preprocessing function (to prepare text for BERT tokenizer)\n",
    "def preprocess_text_for_bert(text):\n",
    "    # Convert to lowercase (for 'uncased' models; skip this for 'cased' models)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing function to 'reviews.text'\n",
    "df_cleaned['cleaned_text'] = df_cleaned['reviews.text'].apply(preprocess_text_for_bert)\n",
    "\n",
    "# Preview the cleaned text\n",
    "print(df_cleaned[['reviews.text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>brand</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I order 3 of them and one of the item is bad q...</td>\n",
       "      <td>i order 3 of them and one of the item is bad q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bulk is always the less expensive way to go fo...</td>\n",
       "      <td>bulk is always the less expensive way to go fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Well they are not Duracell but for the price i...</td>\n",
       "      <td>well they are not duracell but for the price i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Seem to work as well as name brand batteries a...</td>\n",
       "      <td>seem to work as well as name brand batteries a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmazonBasics AAA Performance Alkaline Batterie...</td>\n",
       "      <td>Amazonbasics</td>\n",
       "      <td>Health &amp; Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>These batteries are very long lasting the pric...</td>\n",
       "      <td>these batteries are very long lasting the pric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name         brand  \\\n",
       "0  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "1  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "2  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "3  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "4  AmazonBasics AAA Performance Alkaline Batterie...  Amazonbasics   \n",
       "\n",
       "  primaryCategories  reviews.rating  \\\n",
       "0   Health & Beauty             3.0   \n",
       "1   Health & Beauty             4.0   \n",
       "2   Health & Beauty             5.0   \n",
       "3   Health & Beauty             5.0   \n",
       "4   Health & Beauty             5.0   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  I order 3 of them and one of the item is bad q...   \n",
       "1  Bulk is always the less expensive way to go fo...   \n",
       "2  Well they are not Duracell but for the price i...   \n",
       "3  Seem to work as well as name brand batteries a...   \n",
       "4  These batteries are very long lasting the pric...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  i order 3 of them and one of the item is bad q...  \n",
       "1  bulk is always the less expensive way to go fo...  \n",
       "2  well they are not duracell but for the price i...  \n",
       "3  seem to work as well as name brand batteries a...  \n",
       "4  these batteries are very long lasting the pric...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Tokenization for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  2344,  1017,  1997,  2068,  1998,  2028,  1997,  1996,\n",
      "          8875,  2003,  2919,  3737,  1012,  2003,  4394, 10200,  3500,  2061,\n",
      "          1045,  2031,  2000,  2404,  1037, 27019,  1997, 13061,  2000,  2191,\n",
      "          1996,  6046,  2147,  1012,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the 'cleaned_text' column using BERT tokenizer\n",
    "def tokenize_text(text):\n",
    "    return tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize a single example for testing\n",
    "sample_text = df_cleaned['cleaned_text'][0]\n",
    "tokenized_output = tokenize_text(sample_text)\n",
    "print(tokenized_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the entire dataset (reviews.text)\n",
    "# Store tokenized input IDs and attention masks\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for review in df_cleaned['cleaned_text']:\n",
    "    encoded_review = tokenize_text(review)\n",
    "    input_ids.append(encoded_review['input_ids'])\n",
    "    attention_masks.append(encoded_review['attention_mask'])\n",
    "\n",
    "# Convert lists to tensors for later use with BERT\n",
    "print(\"Tokenization complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up BERT based model for Sentiment Classification\n",
    "we will map both reviews.rating and reviews.text columns to obtain a more accurate sentiment, instead of only the numerical rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping reviews.rating to Sentiment Labels.\n",
    " - For the rating rows that are not being filled, we are telling the machine to take in consideration the text written on that row instead of the rating\n",
    " - Using a Pre-trained Sentiment Analysis Model for reviews.text (finiteautomata, bertweet-base-sentiment-analysis\", Model trained with SemEval 2017 corpus (around ~40k tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 14:32:28.878699: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-15 14:32:28.878751: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-15 14:32:28.879695: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-15 14:32:28.885386: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 14:32:29.630805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 128). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        reviews.text  text_sentiment\n",
      "0  I order 3 of them and one of the item is bad q...             NaN\n",
      "1  Bulk is always the less expensive way to go fo...             NaN\n",
      "2  Well they are not Duracell but for the price i...             NaN\n",
      "3  Seem to work as well as name brand batteries a...             NaN\n",
      "4  These batteries are very long lasting the pric...             NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152/1988594142.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['text_sentiment'] = df_cleaned['reviews.text'].apply(analyze_review_sentiment)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained sentiment analysis model from Hugging Face\n",
    "sentiment_analyzer = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "# Function to analyze review text sentiment using the pre-trained model\n",
    "def analyze_review_sentiment(review_text):\n",
    "    try:\n",
    "        analysis = sentiment_analyzer(review_text)[0]\n",
    "        if analysis['label'] == 'POSITIVE':\n",
    "            return 2  # Positive\n",
    "        elif analysis['label'] == 'NEGATIVE':\n",
    "            return 0  # Negative\n",
    "    except:\n",
    "        return 1  # Neutral if there's an error or too short text, mark as neutral\n",
    "\n",
    "# Apply the sentiment analysis model to 'reviews.text'\n",
    "df_cleaned['text_sentiment'] = df_cleaned['reviews.text'].apply(analyze_review_sentiment)\n",
    "\n",
    "# Verify the text sentiment column is created\n",
    "print(df_cleaned[['reviews.text', 'text_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviews.rating                                       reviews.text  \\\n",
      "0             3.0  I order 3 of them and one of the item is bad q...   \n",
      "1             4.0  Bulk is always the less expensive way to go fo...   \n",
      "2             5.0  Well they are not Duracell but for the price i...   \n",
      "3             5.0  Seem to work as well as name brand batteries a...   \n",
      "4             5.0  These batteries are very long lasting the pric...   \n",
      "\n",
      "   text_sentiment  final_sentiment  \n",
      "0             NaN              1.0  \n",
      "1             NaN              2.0  \n",
      "2             NaN              2.0  \n",
      "3             NaN              2.0  \n",
      "4             NaN              2.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152/3612161423.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['rating_sentiment'] = df_cleaned['reviews.rating'].apply(map_rating_sentiment)\n"
     ]
    }
   ],
   "source": [
    "# Function to map sentiment based on reviews.rating and text sentiment\n",
    "def map_rating_sentiment(row):\n",
    "    if pd.isnull(row['reviews.rating']):  # If rating is missing\n",
    "        return row['text_sentiment']  # Use sentiment from the text\n",
    "    else:\n",
    "        # Map rating to sentiment (adjust the thresholds as needed)\n",
    "        if row['reviews.rating'] >= 4:\n",
    "            return 2  # Positive\n",
    "        elif row['reviews.rating'] == 3:\n",
    "            return 1  # Neutral\n",
    "        else:\n",
    "            return 0  # Negative\n",
    "\n",
    "# Apply the modified sentiment mapping logic\n",
    "df_cleaned['final_sentiment'] = df_cleaned.apply(map_rating_sentiment, axis=1)\n",
    "\n",
    "# Check the final sentiment labels\n",
    "print(df_cleaned[['reviews.rating', 'reviews.text', 'text_sentiment', 'final_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine reviews.rating and reviews.text Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'brand', 'primaryCategories', 'reviews.rating', 'reviews.text',\n",
      "       'cleaned_text', 'text_sentiment', 'final_sentiment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   reviews.rating                                       reviews.text  \\\n",
      "0             3.0  I order 3 of them and one of the item is bad q...   \n",
      "1             4.0  Bulk is always the less expensive way to go fo...   \n",
      "2             5.0  Well they are not Duracell but for the price i...   \n",
      "3             5.0  Seem to work as well as name brand batteries a...   \n",
      "4             5.0  These batteries are very long lasting the pric...   \n",
      "\n",
      "   rating_sentiment  text_sentiment  final_sentiment  \n",
      "0                 1             NaN              NaN  \n",
      "1                 2             NaN              2.0  \n",
      "2                 2             NaN              2.0  \n",
      "3                 2             NaN              2.0  \n",
      "4                 2             NaN              2.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1152/1563251262.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['final_sentiment'] = df_cleaned.apply(\n"
     ]
    }
   ],
   "source": [
    "# Function to combine rating and text sentiment to derive final sentiment\n",
    "def combine_sentiments(rating_sentiment, text_sentiment):\n",
    "    if pd.isnull(rating_sentiment):  # If rating is missing, rely on text sentiment\n",
    "        return text_sentiment\n",
    "    else:\n",
    "        # If the rating is neutral (1), rely more on the text sentiment\n",
    "        if rating_sentiment == 1:  # Neutral rating\n",
    "            return text_sentiment\n",
    "        else:\n",
    "            # Otherwise, prioritize the rating sentiment\n",
    "            return rating_sentiment\n",
    "\n",
    "# Apply the function to combine both sentiments\n",
    "df_cleaned['final_sentiment'] = df_cleaned.apply(\n",
    "    lambda row: combine_sentiments(row['rating_sentiment'], row['text_sentiment']), axis=1\n",
    ")\n",
    "\n",
    "# Check the final sentiment labels\n",
    "print(df_cleaned[['reviews.rating', 'reviews.text', 'rating_sentiment', 'text_sentiment', 'final_sentiment']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready for training!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure input_ids and attention_masks are in list format (if not already).\n",
    "# If they are PyTorch tensors already, skip the cat() step\n",
    "\n",
    "#input_ids = torch.stack(input_ids)  # Stack the list of tensors into a single tensor\n",
    "#attention_masks = torch.stack(attention_masks)  # Do the same for attention masks\n",
    "#THIS LEAD TO ERROR:  input_ids list contains tensors of different lengths. \n",
    "\n",
    "b_input_ids = b_input_ids.squeeze()\n",
    "b_input_mask = b_input_mask.squeeze()# Pad the sequences and stack them into a single tensor\n",
    "\n",
    "\n",
    "# Convert final sentiment labels into a tensor\n",
    "labels = torch.tensor(df_cleaned['final_sentiment'].values)\n",
    "\n",
    "# Split the data into training and validation sets (80% train, 20% validation)\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, test_size=0.2, random_state=42)\n",
    "train_masks, val_masks = train_test_split(attention_masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Move the data to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_inputs, train_masks, train_labels = train_inputs.to(device), train_masks.to(device), train_labels.to(device)\n",
    "val_inputs, val_masks, val_labels = val_inputs.to(device), val_masks.to(device), val_labels.to(device)\n",
    "\n",
    "print(\"Data is ready for training!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT Model Setup\n",
    " - We will set it up for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "\n",
    "# Load pre-trained BERT model with a classification head (3 labels: positive, neutral, negative)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Set up class weights\n",
    "#class_weights = torch.tensor([1.0, 3.0, 1.0])  # ADDED LINE: the Neutral class is being underrepresented\n",
    "\n",
    "# Set up optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Loss function (cross-entropy for classification)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Forward pass: get logits (outputs)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, b_labels)        \n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Extract the loss and logits\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py:1564\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1564\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1578\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/bert/modeling_bert.py:967\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 967\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m    968\u001b[0m device \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m inputs_embeds\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# past_key_values_length\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Training phase\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack the batch\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Clear gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Forward pass: get logits (outputs)\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        loss = criterion(outputs, b_labels)        \n",
    "        # Extract the loss and logits\n",
    "        loss = outputs.loss  # Loss is the first output\n",
    "        logits = outputs.logits  # Logits are the second output\n",
    "        \n",
    "        # Backward pass: compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Training loss: {total_loss / len(train_dataloader)}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_val_loss = 0\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for batch in val_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        with torch.no_grad():  # Disable gradient calculation for validation\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU for evaluation\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.cpu().numpy()\n",
    "\n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "    print(f\"Validation loss: {total_val_loss / len(val_dataloader)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_sentiment\n",
      "2    63606\n",
      "0     4350\n",
      "1        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned['final_sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.78      0.81       850\n",
      "     Neutral       0.00      0.00      0.00         0\n",
      "    Positive       0.99      0.99      0.99     12742\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     13592\n",
      "   macro avg       0.61      0.59      0.60     13592\n",
      "weighted avg       0.98      0.98      0.98     13592\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "        logits = outputs.logits\n",
    "    predictions.append(logits.argmax(dim=1).cpu().numpy())\n",
    "    true_labels.append(b_labels.cpu().numpy())\n",
    "\n",
    "# Flatten predictions and true labels\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Classification report\n",
    "target_names = ['Negative', 'Neutral', 'Positive']\n",
    "labels = [0, 1, 2]  # assuming these are the correct labels\n",
    "print(classification_report(true_labels, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in true_labels: [0 2]\n"
     ]
    }
   ],
   "source": [
    "# Check the unique labels in true_labels\n",
    "print(f\"Unique labels in true_labels: {np.unique(true_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./sentiment_model')\n",
    "tokenizer.save_pretrained('./sentiment_tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_sentiment\n",
      "2    63606\n",
      "0     4350\n",
      "1        2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned['final_sentiment'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
